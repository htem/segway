{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from extract_segId_from_prediction import graph_with_segId_prediction\n",
    "from evaluation_matrix import splits_error,merge_error,rand_voi_split_merge\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import daisy\n",
    "from daisy import Coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def to_pixel_coord_xyz(zyx):\n",
    "    zyx = (daisy.Coordinate(zyx) / daisy.Coordinate((40, 4, 4)))\n",
    "    return daisy.Coordinate((zyx[2], zyx[1], zyx[0]))\n",
    "\n",
    "\n",
    "def get_error_dict(skeleton_path,seg_path,threshold_list):\n",
    "    #skeleton_path = '/n/groups/htem/temcagt/datasets/cb2/segmentation/python_scripts/yh231/cb2_cutout4.csv'\n",
    "    # segment_ds = daisy.open_ds(\n",
    "    #         \"/home/yh231/segmentation/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\",\n",
    "    #         \"volumes/segmentation_0.500\")\n",
    "    #parent_path = '/home/yh231/segmentation/cb2_segmentation/outputs/2019_03/pl2_yumin/cb2_v2/100000/output.zarr'\n",
    "    # parent_path = '/home/yh231/segmentation/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr'\n",
    "    # files = [f for f in os.listdir(parent_path+'/volumes') if re.match(r'segmentation.*',f)]\n",
    "\n",
    "    # #files = ['segmentation_0.500']\n",
    "    # files.sort()\n",
    "    numb_split = []\n",
    "    numb_merge = []\n",
    "    split_error_dict = {}\n",
    "    merge_error_dict = {}\n",
    "    for file in threshold_list:\n",
    "        graph = graph_with_segId_prediction(skeleton_path,seg_path,'volumes/'+ file) # graph \n",
    "        split_error_num, split_list = splits_error(graph)\n",
    "        numb_split.append(split_error_num)\n",
    "        split_error_dict[file]=split_list ##dict == {segmentation_threshold:{sk_id:(((zyx),(zyx)),....),...} }   \n",
    "        merge_error_num, merge_list = merge_error(graph)\n",
    "        numb_merge.append(int(merge_error_num))\n",
    "        merge_error_dict[file]=merge_list ##dict == {segmentation_threshold:{seg_id:([{(zyx),(zyx)},sk1,sk2],....),...} } \n",
    "    return numb_split,numb_merge,split_error_dict,merge_error_dict\n",
    "def get_rand_voi(skeleton_path,seg_path,threshold_list):\n",
    "    rand_split_list, rand_merge_list, voi_split_list, voi_merge_list = [], [], [], []\n",
    "    for file in threshold_list:\n",
    "        graph = graph_with_segId_prediction(skeleton_path,seg_path,'volumes/'+ file)\n",
    "        rand_split, rand_merge, voi_split, voi_merge = rand_voi_split_merge(graph)\n",
    "        rand_split_list.append(rand_split)\n",
    "        rand_merge_list.append(rand_merge)\n",
    "        voi_split_list.append(voi_split)\n",
    "        voi_merge_list.append(voi_merge)\n",
    "    return rand_split_list, rand_merge_list, voi_split_list, voi_merge_list\n",
    "\n",
    "def compare_split_merge(threshold_list, numb_split,numb_merge):\n",
    "    \n",
    "    plt.subplot(211)\n",
    "    plt.plot(list(map(lambda x: x.replace(\"segmentation_\",\"\"),threshold_list)),numb_merge,color = 'b')\n",
    "    plt.ylabel('merge error')\n",
    "    plt.subplot(212)\n",
    "    plt.plot(list(map(lambda x: x.replace(\"segmentation_\",\"\"),threshold_list)),numb_split,color = 'r')\n",
    "    plt.ylabel('split error')\n",
    "    plt.savefig('cutouts5.png')\n",
    "\n",
    "##compare with lines with any model and cutouts\n",
    "def compare_threshold(threshold_list,filename,chosen_matrice,markers,colors,*split_and_merge):#split_and_merge should be modelname,merge,split\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    #print(len(split_and_merge))\n",
    "    for j in range(int(len(split_and_merge)/3)): # zorder; to make points(markers) over the line\n",
    "        ax.plot(split_and_merge[j*3+1],split_and_merge[j*3+2],label = split_and_merge[j*3],color = colors[j],zorder = 1)\n",
    "        for a,b,m,l in zip(split_and_merge[j*3+1],split_and_merge[j*3+2],markers,threshold_list):\n",
    "            if j == 0:\n",
    "                ax.scatter(a,b,marker=m,c=colors[j],label=l.replace(\"segmentation_\",\"\"),zorder = 2)\n",
    "            else:\n",
    "                ax.scatter(a,b,marker=m,c=colors[j],zorder=2)\n",
    "        # for i, labels in enumerate(threshold_list): #add annotation to each point on that line if needed \n",
    "        #     ax.annotate(labels.replace(\"segmentation\",\"\"),(split_and_merge[j*3+1][i],split_and_merge[j*3+2][i]))\n",
    "    ax.legend()\n",
    "    if chosen_matrice == 'number':\n",
    "        ax.set_ylim(bottom=-0.8)\n",
    "        ax.set_xlim(left=-0.8)\n",
    "        plt.xlabel('Merge Error Count')\n",
    "        plt.ylabel('Split Error Count')\n",
    "    elif chosen_matrice == 'rand':\n",
    "        ax.set_ylim(bottom=0)\n",
    "        ax.set_xlim(left=-0.01)\n",
    "        plt.xlabel('Merge Rand')\n",
    "        plt.ylabel('Split Rand')\n",
    "    elif chosen_matrice == 'voi':\n",
    "        ax.set_ylim(bottom=0)\n",
    "        ax.set_xlim(left=-0.01)\n",
    "        plt.xlabel('Merge VOI')\n",
    "        plt.ylabel('Split VOI')\n",
    "    plt.savefig(filename+'_'+chosen_matrice)\n",
    "\n",
    "def compare_threshold_multi_model(\n",
    "    threshold_list,\n",
    "    filename,\n",
    "    skeleton_path,\n",
    "    chosen_matrices,\n",
    "    list_seg_path,\n",
    "    markers = ['.',',','o','v','^','<','>','1','2'],\n",
    "    colors=['b','g','r','c','m','y']):\n",
    "    works = False\n",
    "    if 'number' in chosen_matrices:\n",
    "        split_and_merge_number = []\n",
    "        for seg_path in list_seg_path: \n",
    "            numb_split,numb_merge,_,_ = get_error_dict(skeleton_path,seg_path,threshold_list)\n",
    "            model=re.search(r\"[0-9]+000\",seg_path).group(0) \n",
    "            split_and_merge_number.extend((model,numb_merge,numb_split))\n",
    "        #compare_threshold(threshold_list,filename,'number',markers,colors,*split_and_merge)\n",
    "        works = True\n",
    "    if 'rand' in chosen_matrices:\n",
    "        split_and_merge_rand = []\n",
    "        for seg_path in list_seg_path:\n",
    "            rand_split_list, rand_merge_list,_,_ = get_rand_voi(skeleton_path,seg_path,threshold_list)\n",
    "            model=re.search(r\"[0-9]+000\",seg_path).group(0)\n",
    "            split_and_merge_rand.extend((model,rand_merge_list,rand_split_list))\n",
    "        #compare_threshold(threshold_list,filename,'rand',markers,colors,*split_and_merge_rand)\n",
    "        works = True\n",
    "    if 'voi' in chosen_matrices:\n",
    "        split_and_merge_voi = []\n",
    "        for seg_path in list_seg_path:\n",
    "            _,_, voi_split_list, voi_merge_list = get_rand_voi(skeleton_path,seg_path,threshold_list)\n",
    "            model=re.search(r\"[0-9]+000\",seg_path).group(0)\n",
    "            split_and_merge_voi.extend((model,voi_merge_list,voi_split_list))            \n",
    "        #compare_threshold(threshold_list,filename,'voi',markers,colors,*split_and_merge_voi)\n",
    "        works = True\n",
    "    if not works:\n",
    "        print(\"please provide the correct string for chosen matrices from 'number','rand' or 'voi'\") \n",
    "    return split_and_merge_number,split_and_merge_rand,split_and_merge_voi\n",
    "\n",
    "\n",
    "def print_the_split_error(split_error_dict,seg_path,threshold):\n",
    "    segment_ds = daisy.open_ds(\n",
    "             seg_path,\n",
    "             \"volumes/\"+threshold)\n",
    "    print (threshold)\n",
    "    for skel_id in split_error_dict[threshold]:\n",
    "        print(\"Skeleton: \", skel_id)\n",
    "        errors = split_error_dict[threshold][skel_id]\n",
    "        for error in errors:\n",
    "            for point in error:\n",
    "                #print(point)\n",
    "                print(to_pixel_coord_xyz(point))\n",
    "                print('segid is: %d'%segment_ds[Coordinate(point)])\n",
    "\n",
    "    #return merge_error_dict,split_error_dict\n",
    "\n",
    "def print_the_merge_error(merge_error_dict,threshold):\n",
    "    print (threshold)\n",
    "    for seg_id in merge_error_dict[threshold]:\n",
    "        print(\"Segmentation:\", seg_id)\n",
    "        errors = merge_error_dict[threshold][seg_id]\n",
    "        for error in errors:\n",
    "            print (to_pixel_coord_xyz(error[0][0]))\n",
    "            print ('sk_id is: %d'%error[1])\n",
    "            print (to_pixel_coord_xyz(error[0][1]))\n",
    "            print ('sk_id is: %d'%error[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.300\n",
      "(0.17980817140009964, 0.0, 0.490296647368174, 0.0)\n"
     ]
    }
   ],
   "source": [
    "#tset code for rand and voi\n",
    "skeleton_path = '/n/groups/htem/temcagt/datasets/cb2/segmentation/python_scripts/yh231/cb2_cutout4.csv'\n",
    "seg_path ='/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr'\n",
    "graph = graph_with_segId_prediction(skeleton_path,seg_path,'volumes/segmentation_0.300' )\n",
    "data = rand_voi_split_merge(graph)\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.100\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.200\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.300\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.400\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.500\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.600\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.700\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.800\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.900\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.100\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.200\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.300\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.400\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.500\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.600\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.700\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.800\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.900\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.100\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.200\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.300\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.400\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.500\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.600\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.700\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.800\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.900\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.100\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.200\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.300\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.400\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.500\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.600\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.700\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.800\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.900\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.100\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.200\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.300\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.400\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.500\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.600\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.700\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.800\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.900\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/160000/output.zarr\n",
      "volumes/segmentation_0.100\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/160000/output.zarr\n",
      "volumes/segmentation_0.200\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/160000/output.zarr\n",
      "volumes/segmentation_0.300\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/160000/output.zarr\n",
      "volumes/segmentation_0.400\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/160000/output.zarr\n",
      "volumes/segmentation_0.500\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/160000/output.zarr\n",
      "volumes/segmentation_0.600\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/160000/output.zarr\n",
      "volumes/segmentation_0.700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/160000/output.zarr\n",
      "volumes/segmentation_0.800\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/160000/output.zarr\n",
      "volumes/segmentation_0.900\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/180000/output.zarr\n",
      "volumes/segmentation_0.100\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/180000/output.zarr\n",
      "volumes/segmentation_0.200\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/180000/output.zarr\n",
      "volumes/segmentation_0.300\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/180000/output.zarr\n",
      "volumes/segmentation_0.400\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/180000/output.zarr\n",
      "volumes/segmentation_0.500\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/180000/output.zarr\n",
      "volumes/segmentation_0.600\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/180000/output.zarr\n",
      "volumes/segmentation_0.700\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/180000/output.zarr\n",
      "volumes/segmentation_0.800\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/180000/output.zarr\n",
      "volumes/segmentation_0.900\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.100\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.200\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.300\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.400\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.500\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.600\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.700\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.800\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr\n",
      "volumes/segmentation_0.900\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.100\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.200\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.300\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.400\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.500\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.600\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.700\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.800\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr\n",
      "volumes/segmentation_0.900\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.100\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.200\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.300\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.400\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.500\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.600\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.700\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.800\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr\n",
      "volumes/segmentation_0.900\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.100\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.200\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.300\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.400\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.500\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.600\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.700\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.800\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr\n",
      "volumes/segmentation_0.900\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.100\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.200\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.300\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.400\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.600\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.700\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.800\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr\n",
      "volumes/segmentation_0.900\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/160000/output.zarr\n",
      "volumes/segmentation_0.100\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/160000/output.zarr\n",
      "volumes/segmentation_0.200\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/160000/output.zarr\n",
      "volumes/segmentation_0.300\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/160000/output.zarr\n",
      "volumes/segmentation_0.400\n",
      "/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/160000/output.zarr\n",
      "volumes/segmentation_0.500\n"
     ]
    }
   ],
   "source": [
    "## create the graph of comparing different model \n",
    "threshold_list = ['segmentation_0.100','segmentation_0.200','segmentation_0.300','segmentation_0.400','segmentation_0.500','segmentation_0.600','segmentation_0.700','segmentation_0.800','segmentation_0.900']\n",
    "skeleton_path= '/n/groups/htem/temcagt/datasets/cb2/segmentation/python_scripts/yh231/cb2_cutout4.csv'\n",
    "\n",
    "\n",
    "seg_path_130k ='/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/cb2/130000/output.zarr'\n",
    "\n",
    "seg_path_40k = '/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/40000/output.zarr'\n",
    "seg_path_60k = '/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/60000/output.zarr'\n",
    "seg_path_80k = '/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup00/80000/output.zarr'\n",
    "seg_path_140k = '/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/140000/output.zarr'\n",
    "seg_path_160k = '/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/160000/output.zarr'\n",
    "seg_path_180k = '/n/groups/htem/temcagt/datasets/cb2/segmentation/tri/cb2_segmentation/outputs/2019_03/cb2_synapse_cutout4/setup01/180000/output.zarr'\n",
    "number, rand ,voi = compare_threshold_multi_model(threshold_list,'eval01',skeleton_path,['rand','voi','number'],[seg_path_40k,seg_path_60k,seg_path_80k,seg_path_140k,seg_path_130k,seg_path_160k,seg_path_180k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['.',',','o','v','^','<','>','1','2']\n",
    "colors=['b','g','r','c','m','y','k']\n",
    "compare_threshold(threshold_list,'eval01','voi',markers,colors,*split_and_merge_voi)\n",
    "compare_threshold(threshold_list,'eval01','rand',markers,colors,*split_and_merge_rand)\n",
    "compare_threshold(threshold_list,'eval01','rand',markers,colors,*split_and_merge_rand)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
